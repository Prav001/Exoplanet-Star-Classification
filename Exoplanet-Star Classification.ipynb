{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b6b2254965f03e535cb73f1abf3bba4ec5c3cfe4"
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-23T03:21:16.549259Z",
     "iopub.status.busy": "2023-03-23T03:21:16.548800Z",
     "iopub.status.idle": "2023-03-23T03:21:16.562383Z",
     "shell.execute_reply": "2023-03-23T03:21:16.561728Z",
     "shell.execute_reply.started": "2023-03-23T03:21:16.549216Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy import ndimage\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score,RepeatedStratifiedKFold,RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c17634d1b3ecb3fd7b361d19c8774df26dac4ea2"
   },
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "8aef4d6898bf06a2414a3a675a1fa9400f97cbd6",
    "execution": {
     "iopub.execute_input": "2023-03-23T03:21:18.789048Z",
     "iopub.status.busy": "2023-03-23T03:21:18.788675Z",
     "iopub.status.idle": "2023-03-23T03:21:24.295502Z",
     "shell.execute_reply": "2023-03-23T03:21:24.294652Z",
     "shell.execute_reply.started": "2023-03-23T03:21:18.788960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:  (5087,)\n",
      "y_test.shape:  (570,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>-160.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>-73.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>484.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>323.33</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>-970.88</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7   FLUX.8  \\\n",
       "0    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   -96.27   \n",
       "1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   -85.33   \n",
       "2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   486.39   \n",
       "3   326.52   347.39   302.35   298.13   317.74   312.70  322.33   311.31   \n",
       "4 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34 -1022.71   \n",
       "\n",
       "   FLUX.9  FLUX.10  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0  -79.89  -160.17  ...     -78.07    -102.15    -102.15      25.13   \n",
       "1  -83.97   -73.38  ...      -3.28     -32.21     -32.21     -24.89   \n",
       "2  436.56   484.39  ...     -71.69      13.31      13.31     -29.89   \n",
       "3  312.42   323.33  ...       5.71      -3.73      -3.73      30.05   \n",
       "4 -989.57  -970.88  ...    -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Original Dataset: \n",
    "https://www.kaggle.com/datasets/keplersmachines/kepler-labelled-time-series-data\n",
    "''' \n",
    "train_dataset_path  = \"./exoTrain.csv\"\n",
    "test_dataset_path = \"./exoTest.csv\"\n",
    "\n",
    "X_train = pd.read_csv(train_dataset_path, encoding = \"ISO-8859-1\")\n",
    "X_test = pd.read_csv(test_dataset_path, encoding = \"ISO-8859-1\")\n",
    "\n",
    "\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_train.dropna(axis=0, subset=['LABEL'], inplace=True)\n",
    "y_train = X_train.LABEL\n",
    "y_test = X_test.LABEL\n",
    "\n",
    "X_train.drop(['LABEL'], axis=1, inplace=True)\n",
    "X_test.drop(['LABEL'], axis=1, inplace=True)\n",
    "\n",
    "# Store original column names\n",
    "original_columns = X_train.columns\n",
    "\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of rows = number of stars \n",
    "2. Each star has a binary label (represented by column LABEL) of 2 or 1. '2' indicate that that the star is confirmed to have at least one exoplanet in orbit.\n",
    "3. Remaining columns (FLUX.1 and so on) represent the recorded flux at given time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e03e00f593729a6fb36841cde640a0cb366bf4f"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "504e0ecddfafc27cdf49022f2950566373c0d6fe",
    "execution": {
     "iopub.execute_input": "2023-03-23T03:21:24.677283Z",
     "iopub.status.busy": "2023-03-23T03:21:24.676998Z",
     "iopub.status.idle": "2023-03-23T03:21:27.390821Z",
     "shell.execute_reply": "2023-03-23T03:21:27.389877Z",
     "shell.execute_reply.started": "2023-03-23T03:21:24.677228Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X_train,X_test,original_columns):\n",
    "    \n",
    "    # Preprocessing for numerical data\n",
    "    imputer= SimpleImputer(strategy='median')\n",
    "    imputer.fit(X_train)\n",
    "\n",
    "    X_train_imputed= pd.DataFrame(imputer.transform(X_train))\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test))\n",
    "\n",
    "    # Assign original column names back to the DataFrames\n",
    "    X_train_imputed.columns = original_columns\n",
    "    X_test_imputed.columns = original_columns\n",
    "\n",
    "    print(\"X_train shape after imputation: \", X_train_imputed.shape)\n",
    "    print(\"X_test.shape after imputation: \", X_test_imputed.shape)\n",
    "\n",
    "    return X_train_imputed,X_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape after imputation:  (5087, 3197)\n",
      "X_test.shape imputation:  (570, 3197)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test= preprocess_data(X_train,X_test,original_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T02:39:09.699710Z",
     "iopub.status.busy": "2023-03-23T02:39:09.699397Z",
     "iopub.status.idle": "2023-03-23T02:39:09.702804Z",
     "shell.execute_reply": "2023-03-23T02:39:09.702126Z",
     "shell.execute_reply.started": "2023-03-23T02:39:09.699652Z"
    }
   },
   "source": [
    "## Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "87e08df975d26a6d05feb1005931fa20ad450fde",
    "execution": {
     "iopub.execute_input": "2023-03-23T03:21:27.392794Z",
     "iopub.status.busy": "2023-03-23T03:21:27.392241Z",
     "iopub.status.idle": "2023-03-23T03:21:27.434915Z",
     "shell.execute_reply": "2023-03-23T03:21:27.433919Z",
     "shell.execute_reply.started": "2023-03-23T03:21:27.392735Z"
    }
   },
   "outputs": [],
   "source": [
    "class ExoPlanetProcessor:\n",
    "\n",
    "    def __init__(self, fourier=True, normalize=True, gaussian=True, standardize=True):\n",
    "        self.normalize = normalize\n",
    "        self.gaussian = gaussian\n",
    "        self.standardize = standardize\n",
    "\n",
    "    def fourier_transform(self, X):\n",
    "        return np.abs(fft(X, n=X.size))\n",
    "\n",
    "    def process(self, df_train_x, df_valid_x):\n",
    "        \n",
    "        # Normalize\n",
    "        if self.normalize:\n",
    "            print(\"Normalizing Dataset\")\n",
    "            df_train_x = pd.DataFrame(normalize(df_train_x))\n",
    "            df_valid_x = pd.DataFrame(normalize(df_valid_x))\n",
    "\n",
    "        # Gaussian filter to smooth out data\n",
    "        if self.gaussian:\n",
    "            print(\"Applying Gaussian Filter...\")\n",
    "            df_train_x = ndimage.gaussian_filter(df_train_x, sigma=10)\n",
    "            df_valid_x = ndimage.gaussian_filter(df_valid_x, sigma=10)\n",
    "\n",
    "        if self.standardize:\n",
    "            # Standardize X data\n",
    "            print(\"Standardizing...\")\n",
    "            std_scaler = StandardScaler()\n",
    "            df_train_x = std_scaler.fit_transform(df_train_x)\n",
    "            df_valid_x = std_scaler.transform(df_valid_x)\n",
    "\n",
    "        df_train_x= pd.DataFrame(df_train_x)\n",
    "        df_valid_x= pd.DataFrame(df_valid_x)\n",
    "        return df_train_x, df_valid_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "90a0ea43b0ef441d5ff094adec4d6a1e2030ab58",
    "execution": {
     "iopub.execute_input": "2023-03-23T03:21:27.503480Z",
     "iopub.status.busy": "2023-03-23T03:21:27.503180Z",
     "iopub.status.idle": "2023-03-23T03:21:30.499379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing Dataset\n",
      "Applying Gaussian Filter...\n",
      "Standardizing...\n",
      "Size after processing\n",
      "X_train.shape:  (5087, 3197)\n",
      "X_test.shape:  (570, 3197)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156857</td>\n",
       "      <td>0.157092</td>\n",
       "      <td>0.157533</td>\n",
       "      <td>0.158134</td>\n",
       "      <td>0.158812</td>\n",
       "      <td>0.159460</td>\n",
       "      <td>0.159918</td>\n",
       "      <td>0.160006</td>\n",
       "      <td>0.159474</td>\n",
       "      <td>0.158029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.804519</td>\n",
       "      <td>-0.753474</td>\n",
       "      <td>-0.706362</td>\n",
       "      <td>-0.663767</td>\n",
       "      <td>-0.626225</td>\n",
       "      <td>-0.594201</td>\n",
       "      <td>-0.568086</td>\n",
       "      <td>-0.548237</td>\n",
       "      <td>-0.534874</td>\n",
       "      <td>-0.528142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146127</td>\n",
       "      <td>0.146319</td>\n",
       "      <td>0.146673</td>\n",
       "      <td>0.147148</td>\n",
       "      <td>0.147664</td>\n",
       "      <td>0.148116</td>\n",
       "      <td>0.148352</td>\n",
       "      <td>0.148197</td>\n",
       "      <td>0.147412</td>\n",
       "      <td>0.145711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.800650</td>\n",
       "      <td>-0.749602</td>\n",
       "      <td>-0.702473</td>\n",
       "      <td>-0.659852</td>\n",
       "      <td>-0.622281</td>\n",
       "      <td>-0.590226</td>\n",
       "      <td>-0.564082</td>\n",
       "      <td>-0.544211</td>\n",
       "      <td>-0.530831</td>\n",
       "      <td>-0.524090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125147</td>\n",
       "      <td>0.125250</td>\n",
       "      <td>0.125431</td>\n",
       "      <td>0.125649</td>\n",
       "      <td>0.125833</td>\n",
       "      <td>0.125888</td>\n",
       "      <td>0.125671</td>\n",
       "      <td>0.125022</td>\n",
       "      <td>0.123719</td>\n",
       "      <td>0.121493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.793121</td>\n",
       "      <td>-0.742070</td>\n",
       "      <td>-0.694912</td>\n",
       "      <td>-0.652243</td>\n",
       "      <td>-0.614614</td>\n",
       "      <td>-0.582501</td>\n",
       "      <td>-0.556304</td>\n",
       "      <td>-0.536387</td>\n",
       "      <td>-0.522977</td>\n",
       "      <td>-0.516219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.094507</td>\n",
       "      <td>0.094476</td>\n",
       "      <td>0.094392</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>0.093902</td>\n",
       "      <td>0.093352</td>\n",
       "      <td>0.092445</td>\n",
       "      <td>0.091043</td>\n",
       "      <td>0.088948</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.782423</td>\n",
       "      <td>-0.731373</td>\n",
       "      <td>-0.684174</td>\n",
       "      <td>-0.641437</td>\n",
       "      <td>-0.603726</td>\n",
       "      <td>-0.571527</td>\n",
       "      <td>-0.545250</td>\n",
       "      <td>-0.525269</td>\n",
       "      <td>-0.511812</td>\n",
       "      <td>-0.505030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.055045</td>\n",
       "      <td>0.054833</td>\n",
       "      <td>0.054390</td>\n",
       "      <td>0.053692</td>\n",
       "      <td>0.052690</td>\n",
       "      <td>0.051318</td>\n",
       "      <td>0.049474</td>\n",
       "      <td>0.047047</td>\n",
       "      <td>0.043872</td>\n",
       "      <td>0.039745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769246</td>\n",
       "      <td>-0.718204</td>\n",
       "      <td>-0.670956</td>\n",
       "      <td>-0.628134</td>\n",
       "      <td>-0.590318</td>\n",
       "      <td>-0.558010</td>\n",
       "      <td>-0.531631</td>\n",
       "      <td>-0.511565</td>\n",
       "      <td>-0.498048</td>\n",
       "      <td>-0.491235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FLUX.1    FLUX.2    FLUX.3    FLUX.4    FLUX.5    FLUX.6    FLUX.7  \\\n",
       "0  0.156857  0.157092  0.157533  0.158134  0.158812  0.159460  0.159918   \n",
       "1  0.146127  0.146319  0.146673  0.147148  0.147664  0.148116  0.148352   \n",
       "2  0.125147  0.125250  0.125431  0.125649  0.125833  0.125888  0.125671   \n",
       "3  0.094507  0.094476  0.094392  0.094222  0.093902  0.093352  0.092445   \n",
       "4  0.055045  0.054833  0.054390  0.053692  0.052690  0.051318  0.049474   \n",
       "\n",
       "     FLUX.8    FLUX.9   FLUX.10  ...  FLUX.3188  FLUX.3189  FLUX.3190  \\\n",
       "0  0.160006  0.159474  0.158029  ...  -0.804519  -0.753474  -0.706362   \n",
       "1  0.148197  0.147412  0.145711  ...  -0.800650  -0.749602  -0.702473   \n",
       "2  0.125022  0.123719  0.121493  ...  -0.793121  -0.742070  -0.694912   \n",
       "3  0.091043  0.088948  0.085919  ...  -0.782423  -0.731373  -0.684174   \n",
       "4  0.047047  0.043872  0.039745  ...  -0.769246  -0.718204  -0.670956   \n",
       "\n",
       "   FLUX.3191  FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0  -0.663767  -0.626225  -0.594201  -0.568086  -0.548237  -0.534874  -0.528142  \n",
       "1  -0.659852  -0.622281  -0.590226  -0.564082  -0.544211  -0.530831  -0.524090  \n",
       "2  -0.652243  -0.614614  -0.582501  -0.556304  -0.536387  -0.522977  -0.516219  \n",
       "3  -0.641437  -0.603726  -0.571527  -0.545250  -0.525269  -0.511812  -0.505030  \n",
       "4  -0.628134  -0.590318  -0.558010  -0.531631  -0.511565  -0.498048  -0.491235  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process dataset\n",
    "EPP = ExoPlanetProcessor(\n",
    "    fourier=False,\n",
    "    normalize=True,\n",
    "    gaussian=True,\n",
    "    standardize=True)\n",
    "\n",
    "X_train, X_test = EPP.process(X_train, X_test)\n",
    "\n",
    "# Assign original column names back to the DataFrames\n",
    "X_train.columns = original_columns\n",
    "X_test.columns = original_columns\n",
    "\n",
    "\n",
    "print(\"Size after processing\")\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4783cdb1902414c346e39c709b5619788e4b748"
   },
   "source": [
    "# 1. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T03:21:30.500679Z",
     "iopub.status.busy": "2023-03-23T03:21:30.500410Z"
    }
   },
   "outputs": [],
   "source": [
    "def rfc(X_train,y_train):\n",
    "    # Define model\n",
    "    model_rfc = RandomForestClassifier(n_estimators=30, random_state=0)\n",
    "\n",
    "\n",
    "    model_rfc.fit(X_train, y_train)\n",
    "    y_pred_rfc = model_rfc.predict(X_test)\n",
    "\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=5, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model_rfc, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # summarize performance\n",
    "    print('Mean Accuracy: %.3f' % np.mean(scores))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred_rfc)\n",
    "    precision = precision_score(y_test, y_pred_rfc)\n",
    "    recall = recall_score(y_test, y_pred_rfc)\n",
    "\n",
    "    print(f\"Accuracy using RandomForestClassifier: %.3f\"%accuracy)\n",
    "    print(f\"Precision using RandomForestClassifier: %.3f\"%precision)\n",
    "    print(\"Recall using RandomForestClassifier: %.3f\" %recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "1b8f75a0a1976000bc34e71a65c512d124825097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.999\n",
      "Accuracy using RandomForestClassifier: 0.991\n",
      "Precision using RandomForestClassifier: 0.991\n",
      "Recall using RandomForestClassifier: 1.000\n"
     ]
    }
   ],
   "source": [
    "rfc(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Random Forest With Bootstrap Class Weighting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_with_bootstrap(X_train,y_train):\n",
    "    model_rfc_bcw = RandomForestClassifier(n_estimators=30,random_state=0,class_weight='balanced_subsample')\n",
    "    model_rfc_bcw.fit(X_train, y_train)\n",
    "    y_pred_rfc_bcw = model_rfc_bcw.predict(X_test)\n",
    "    \n",
    "    accuracy_rfc_bcw = accuracy_score(y_test, y_pred_rfc_bcw)\n",
    "    precision_rfc_bcw = precision_score(y_test, y_pred_rfc_bcw)\n",
    "    recall_rfc_bcw = recall_score(y_test, y_pred_rfc_bcw)\n",
    "\n",
    "    print(f\"Accuracy using Bootstrap Class Weighting: %.3f\"%accuracy_rfc_bcw)\n",
    "    print(f\"Precision using Bootstrap Class Weighting: %.3f\"%precision_rfc_bcw)\n",
    "    print(\"Recall using Bootstrap Class Weighting: %.3f\" %recall_rfc_bcw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Bootstrap Class Weighting: 0.991\n",
      "Precision using Bootstrap Class Weighting: 0.991\n",
      "Recall using Bootstrap Class Weighting: 1.000\n"
     ]
    }
   ],
   "source": [
    "rfc_with_bootstrap(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using Bagging Classifier\n",
    "\n",
    "We are dealing with imbalanced classification problem so can't use usual ML models without accounting for dataset class imbalance. Here I use bagging classifier as first approach to deal with thhat problem.\n",
    "\n",
    "https://machinelearningmastery.com/what-is-imbalanced-classification/\n",
    "\n",
    "1. Bagging classifier is an ensemble classifier which is created using multiple estimators which can be trained using different sampling techniques including bagging or bootstrap aggregation (samples drawn with replacement). \n",
    "\n",
    "2. Bagging classifier helps reduce the variance of individual estimators by sampling technique and combining the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_classifier(X_train, y_train):\n",
    "    \n",
    "    # deafault base estimator is a DecisionTreeClassifier.\n",
    "\n",
    "    bagging = BaggingClassifier(n_estimators=10, random_state=0)\n",
    "    bagging.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_bagging = bagging.predict(X_test)\n",
    "\n",
    "    accuracy_bag = accuracy_score(y_test, y_pred_bagging)\n",
    "    precision_bag = precision_score(y_test, y_pred_bagging)\n",
    "    recall_bag = recall_score(y_test, y_pred_bagging)\n",
    "    \n",
    "    print(f\"Accuracy using Bagging Classifier: %.3f\"%accuracy_bag)\n",
    "    print(f\"Precision using Bagging Classifier: %.3f\"%precision_bag)\n",
    "    print(f\"Recall using Bagging Classifier: %.3f\"%recall_bag)\n",
    "\n",
    "    # Model scores on test and training data\n",
    "    print('Model training Score: %.3f' %bagging.score(X_train, y_train))\n",
    "    print('Model test Score: %.3f ' %bagging.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Bagging Classifier: 0.991\n",
      "Precision using Bagging Classifier: 0.991\n",
      "Recall using Bagging Classifier: 1.000\n",
      "Model training Score: 1.000\n",
      "Model test Score: 0.991 \n"
     ]
    }
   ],
   "source": [
    "bagging_classifier(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Bagging with Random Forest Classifier as Base Estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_classifier_rgb(X_train, y_train):\n",
    "    rfc_bagging = BaggingClassifier(base_estimator=RandomForestClassifier(),n_estimators=10, random_state=0)\n",
    "    rfc_bagging.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_rfc_bagging = rfc_bagging.predict(X_test)\n",
    "\n",
    "    accuracy_bag_rfc = accuracy_score(y_test, y_pred_rfc)\n",
    "    precision_bag_rfc = precision_score(y_test, y_pred_rfc)\n",
    "    recall_bag_rfc= recall_score(y_test, y_pred_rfc)\n",
    "    print(f\"Accuracy using Bagging Classifier with RFC: %.3f\"%accuracy_bag_rfc)\n",
    "    print(f\"Precision using Bagging Classifier with RFC: %.3f\"%precision_bag_rfc)\n",
    "    print(f\"Recall using Bagging Classifier with RFC: %.3f\"%recall_bag_rfc)\n",
    "\n",
    "    # Model scores on test and training data\n",
    "    print('Model training Score: %.3f' %rfc_bagging.score(X_train, y_train))\n",
    "    print('Model test Score: %.3f ' %rfc_bagging.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Bagging Classifier with RFC: 0.991\n",
      "Precision using Bagging Classifier with RFC: 0.991\n",
      "Recall using Bagging Classifier with RFC: 1.000\n",
      "Model training Score: 1.000\n",
      "Model test Score: 0.991 \n"
     ]
    }
   ],
   "source": [
    "bagging_classifier_rgb(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Bagging with Support Vector Classifier as Base Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_classifier_svc(X_train, y_train):\n",
    "    \n",
    "    #First just fit data using classic SVC for test purpose \n",
    "    model_svc = svm.SVC()\n",
    "\n",
    "    model_svc.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_svc = model_svc.predict(X_test)\n",
    "\n",
    "    accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "    precision_svc = precision_score(y_test, y_pred_svc)\n",
    "    recall_svc = recall_score(y_test, y_pred_svc)\n",
    "\n",
    "    print(f\"Accuracy using SVC: %.3f\"%accuracy_svc)\n",
    "    print(f\"Precision using SVC: %.3f\"%precision_svc)\n",
    "    print(f\"Recall using SVC: %.3f\"%precision_svc)\n",
    "    \n",
    "    # Now using bagging classfier\n",
    "    svc_bagging = BaggingClassifier(base_estimator=svm.SVC(),n_estimators=10, random_state=0)\n",
    "    svc_bagging.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_svc_bagging = svc_bagging.predict(X_test)\n",
    "\n",
    "    accuracy_bag_svc = accuracy_score(y_test, y_pred_svc_bagging)\n",
    "    precision_bag_svc = precision_score(y_test, y_pred_svc_bagging)\n",
    "    recall_bag_svc = recall_score(y_test, y_pred_svc_bagging)\n",
    "\n",
    "    print(f\"Accuracy using Bagging Classifier with SVC: %.3f\"%accuracy)\n",
    "    print(f\"Precision using Bagging Classifier with SVC: %.3f\"%precision)\n",
    "    print(f\"Recall using Bagging Classifier with SVC: %.3f\"%precision)\n",
    "    \n",
    "    print('Model training Score: %.3f' %bagging.score(X_train, y_train))\n",
    "    print('Model test Score: %.3f ' %bagging.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using SVC: 0.991\n",
      "Precision using SVC: 0.991\n",
      "Recall using SVC: 0.991\n",
      "Accuracy using Bagging Classifier with SVC: 0.991\n",
      "Precision using Bagging Classifier with SVC: 0.991\n",
      "Recall using Bagging Classifier with SVC: 0.991\n",
      "Model training Score: 1.000\n",
      "Model test Score: 0.991 \n"
     ]
    }
   ],
   "source": [
    "bagging_classifier_svc(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
